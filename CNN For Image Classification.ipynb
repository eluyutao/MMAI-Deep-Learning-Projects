{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MMAI 894 Exercise 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eluyutao/MMAI-Deep-Learning-Projects/blob/main/CNN%20For%20Image%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwG5uxEpKaNL"
      },
      "source": [
        "# MMAI 894 - Exercise 2\n",
        "## Convolutional artificial neural network : Image classification\n",
        "The goal of this excercise is to build a convolutional neural network using the tensorflow/keras library. We will be using the MNIST dataset.\n",
        "Submission instructions:\n",
        "\n",
        "- You cannot edit this notebook directly. Save a copy to your drive, and make sure to identify yourself in the title using name and student number\n",
        "- Do not insert new cells before the final one (titled \"Further exploration\") \n",
        "- Verify that your notebook can _restart and run all_. \n",
        "- Select File -> Download as .py (important! not as ipynb)\n",
        "- Rename the file: `studentID_lastname_firstname_ex2.py`\n",
        "- The mark will be assessed on the implementation of the functions with #TODO\n",
        "- **Do not change anything outside the functions**  unless in the further exploration section\n",
        "- As you are encouraged to explore the network configuration, 20% of the mark is based on final accuracy. \n",
        "- Note: You do not have to answer the questions in thie notebook as part of your submission. They are meant to guide you.\n",
        "\n",
        "- You should not need to use any additional libraries other than the ones listed below. You may want to import additional modules from those libraries, however."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-DUt8ROKlvw"
      },
      "source": [
        "# Import modules\n",
        "# Add modules as needed\n",
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For windows laptops add following 2 lines:\n",
        "# import matplotlib\n",
        "# matplotlib.use('agg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models, layers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arrbzOo4LR9q"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4wT7dbPLTNZ"
      },
      "source": [
        "def load_data():\n",
        "    # Import MNIST dataset from openml\n",
        "    dataset = fetch_openml('mnist_784', version=1, data_home=None)\n",
        "\n",
        "    # Data preparation\n",
        "    raw_X = dataset['data']\n",
        "    raw_Y = dataset['target']\n",
        "    return raw_X, raw_Y\n",
        "\n",
        "raw_X, raw_Y = load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRp1jQTrLc39"
      },
      "source": [
        "## Consider the following\n",
        "- Same as excercise 1\n",
        "- what shape should x be for a convolutional network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mG0hdDRLZgD"
      },
      "source": [
        "def clean_data(raw_X, raw_Y):\n",
        "    # TODO: clean and QA raw_X and raw_Y\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    cleaned_X = raw_X / 255\n",
        "    cleaned_Y = keras.utils.to_categorical(raw_Y, num_classes=10)\n",
        "    cleaned_X = cleaned_X.values.reshape(-1, 28,28, 1)\n",
        "\n",
        "    \n",
        "    return cleaned_X, cleaned_Y\n",
        "\n",
        "cleaned_X, cleaned_Y = clean_data(raw_X, raw_Y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5OYgzj7NU_y"
      },
      "source": [
        "#### Data split\n",
        "\n",
        "- Split your data into a train set (50%), validation set (20%) and a test set (30%). You can use scikit-learn's train_test_split function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7HIVDNNYap"
      },
      "source": [
        "def split_data(cleaned_X, cleaned_Y):\n",
        "    # TODO: split the data\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(cleaned_X, cleaned_Y, test_size=0.5, train_size=0.5, random_state=1)\n",
        "    X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.6, train_size=0.4, random_state=1)\n",
        "    \n",
        "    return X_val, X_test, X_train, Y_val, Y_test, Y_train\n",
        "\n",
        "X_val, X_test, X_train, Y_val, Y_test, Y_train = split_data(cleaned_X, cleaned_Y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_z08TdNada"
      },
      "source": [
        "### Model\n",
        "\n",
        "#### Neural network structure\n",
        "\n",
        "This time, the exact model architecture is left to you to explore.  \n",
        "Keep the number of parameters below 2,000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKAx26EDN3Yk"
      },
      "source": [
        "def build_model():\n",
        "    # TODO: build the model, \n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(784, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def compile_model(model):\n",
        "    # TODO: compile the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
        "    # TODO: train the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        Y_train,\n",
        "        batch_size=128,\n",
        "        epochs=12,\n",
        "        verbose=2,\n",
        "        validation_data=(X_val, Y_val))\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def eval_model(model, X_test, Y_test):\n",
        "    # TODO: evaluate the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg5E9ChPOt_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f1886d-4234-4fe6-ed3f-820b2f7d40c6"
      },
      "source": [
        "## You may use this space (and add additional cells for exploration)\n",
        "\n",
        "model = build_model()\n",
        "model = compile_model(model)\n",
        "model, history = train_model(model, X_train, Y_train, X_val, Y_val)\n",
        "test_loss, test_accuracy = eval_model(model, X_test, Y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 784)       7840      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 784)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 128)       903296    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         147584    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                73792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,133,162\n",
            "Trainable params: 1,133,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/12\n",
            "274/274 - 28s - loss: 0.2244 - accuracy: 0.9296 - val_loss: 0.0817 - val_accuracy: 0.9746 - 28s/epoch - 103ms/step\n",
            "Epoch 2/12\n",
            "274/274 - 24s - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0466 - val_accuracy: 0.9851 - 24s/epoch - 89ms/step\n",
            "Epoch 3/12\n",
            "274/274 - 24s - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0471 - val_accuracy: 0.9852 - 24s/epoch - 88ms/step\n",
            "Epoch 4/12\n",
            "274/274 - 24s - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0419 - val_accuracy: 0.9859 - 24s/epoch - 88ms/step\n",
            "Epoch 5/12\n",
            "274/274 - 24s - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0500 - val_accuracy: 0.9837 - 24s/epoch - 88ms/step\n",
            "Epoch 6/12\n",
            "274/274 - 24s - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0429 - val_accuracy: 0.9885 - 24s/epoch - 88ms/step\n",
            "Epoch 7/12\n",
            "274/274 - 24s - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0424 - val_accuracy: 0.9871 - 24s/epoch - 88ms/step\n",
            "Epoch 8/12\n",
            "274/274 - 24s - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0387 - val_accuracy: 0.9885 - 24s/epoch - 88ms/step\n",
            "Epoch 9/12\n",
            "274/274 - 24s - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0451 - val_accuracy: 0.9875 - 24s/epoch - 88ms/step\n",
            "Epoch 10/12\n",
            "274/274 - 24s - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0537 - val_accuracy: 0.9869 - 24s/epoch - 87ms/step\n",
            "Epoch 11/12\n",
            "274/274 - 26s - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0472 - val_accuracy: 0.9870 - 26s/epoch - 94ms/step\n",
            "Epoch 12/12\n",
            "274/274 - 26s - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0496 - val_accuracy: 0.9884 - 26s/epoch - 94ms/step\n",
            "657/657 [==============================] - 9s 13ms/step - loss: 0.0495 - accuracy: 0.9892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_vfTiLsubUAF"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}